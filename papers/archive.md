### Model-based RL
1. **Sample-Efficient Reinforcement Learning with Stochastic Ensemble Value Expansion** NIPS2018. [paper](https://arxiv.org/abs/1807.01675)

    *Jacob Buckman, Danijar Hafner, George Tucker, Eugene Brevdo, Honglak Lee*

2. **Model-Based Value Estimation for Efficient Model-Free Reinforcement Learning**  ICML2018.[paper](https://arxiv.org/abs/1803.00101)

    *Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael I. Jordan, Joseph E. Gonzalez, Sergey Levine* 
    
3. **Value Prediction Network** NIPS2017. [paper](https://arxiv.org/abs/1707.03497)

    *Vladimir Feinberg, Alvin Wan, Ion Stoica, Michael I. Jordan, Joseph E. Gonzalez, Sergey Levine*
    
4. **Imagination-Augmented Agents for Deep Reinforcement Learning** NIPS2017. [paper](https://arxiv.org/abs/1707.06203)

    *Théophane Weber, Sébastien Racanière, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdomènech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra*
    
5. **Continuous Deep Q-Learning with Model-based Acceleration** ICML2016. [paper](https://arxiv.org/abs/1603.00748)
    
    *Shixiang Gu, Timothy Lillicrap, Ilya Sutskever, Sergey Levine*

6. **Uncertainty-driven Imagination for Continuous Deep Reinforcement Learning** CoRL2017. [paper](http://proceedings.mlr.press/v78/kalweit17a/kalweit17a.pdf)
    
    *Gabriel Kalweit, Joschka Boedecker*
    
7. **Model-Ensemble Trust-Region Policy Optimization** ICLR2018. [paper](https://arxiv.org/abs/1802.10592)
    
    *Thanard Kurutach, Ignasi Clavera, Yan Duan, Aviv Tamar, Pieter Abbeel*

8. **Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models** NIPS2018. [paper](https://arxiv.org/abs/1805.12114)
    
    *Kurtland Chua, Roberto Calandra, Rowan McAllister, Sergey Levine*
    
9. **Dyna, an integrated architecture for learning, planning, and reacting** ACM1991. [paper](https://dl.acm.org/citation.cfm?id=122377)
    
    *Sutton, Richard S*
    
10. **Learning Continuous Control Policies by Stochastic Value Gradients** NIPS 2015. [paper](https://arxiv.org/abs/1510.09142)
    
    *Nicolas Heess, Greg Wayne, David Silver, Timothy Lillicrap, Yuval Tassa, Tom Erez*
    
11. **Imagination-Augmented Agents for Deep Reinforcement Learning** NIPS 2017. [paper](https://arxiv.org/abs/1707.06203)

    *Théophane Weber, Sébastien Racanière, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdomènech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra*
    
12. **Learning and Policy Search in Stochastic Dynamical Systems with Bayesian Neural Networks** ICLR 2017. [paper](https://arxiv.org/abs/1605.07127)
    
    *Stefan Depeweg, José Miguel Hernández-Lobato, Finale Doshi-Velez, Steffen Udluft*
    
    
### Distributed Training
1. **Asynchronous Methods for Deep Reinforcement Learning** ICML 2016. [paper](https://arxiv.org/pdf/1602.01783.pdf)
     
    *Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu*

2. **GA3C: GPU-based A3C for Deep Reinforcement Learning** NIPS 2016. [paper](https://www.researchgate.net/publication/310610848_GA3C_GPU-based_A3C_for_Deep_Reinforcement_Learning)

    *Iuri Frosio, Stephen Tyree Jason Clemons Jan Kautz*

3. **Distributed Prioritized Experience Replay** ICLR 2018. [paper](https://openreview.net/pdf?id=H1Dy---0Z)

    *Dan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado van Hasselt, David Silver*

4. **IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures** ICML 2018. [paper](https://arxiv.org/abs/1802.01561)
     
    *Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane Legg, Koray Kavukcuoglu*
    
5. **Distributed Distributional Deterministic Policy Gradients** ICLR 2018. [paper](https://arxiv.org/pdf/1804.08617.pdf)

    *Gabriel Barth-Maron, Matthew W. Hoffman, David Budden, Will Dabney, Dan Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, Timothy Lillicrap*

6. **Emergence of Locomotion Behaviours in Rich Environments** arXiv. [paper](https://arxiv.org/abs/1707.02286)

    *Nicolas Heess, Dhruva TB, Srinivasan Sriram, Jay Lemmon, Josh Merel, Greg Wayne, Yuval Tassa, Tom Erez, Ziyu Wang, S. M. Ali Eslami, Martin Riedmiller, David Silver*

7. **Recurrent Experience Replay in Distributed Reinforcement Learning** ICLR 2019. [paper](https://openreview.net/pdf?id=r1lyTjAqYX)

    *Steven Kapturowski, Georg Ostrovski, John Quan, Remi Munos, Will Dabney*

8. **GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning** CoRL 2018. [paper](https://arxiv.org/abs/1810.05762)

    *Jacky Liang, Viktor Makoviychuk, Ankur Handa, Nuttapong Chentanez, Miles Macklin, Dieter Fox*
    
9. **SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark** CoRL 2018. [paper](https://surreal.stanford.edu/img/surreal-corl2018.pdf)

    *Linxi Fan, Yuke Zhu, Jiren Zhu, Zihua Liu, Orien Zeng, Anchit Gupta, Joan Creus-Costa, Silvio Savarese, Li Fei-Fei*
